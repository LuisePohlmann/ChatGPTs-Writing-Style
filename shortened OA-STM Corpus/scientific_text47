Adaptive resource configuration for Cloud infrastructure management  Abstract To guarantee the vision of Cloud Computing QoS goals between the Cloud provider and the customer have to be dynamically met. This so-called Service Level Agreement (SLA) enactment should involve little human-based interaction in order to guarantee the scalability and efficient resource utilization of the system. To achieve this we start from Autonomic Computing, examine the autonomic control loop and adapt it to govern Cloud Computing infrastructures. We first hierarchically structure all possible adaptation actions into so-called escalation levels. We then focus on one of these levels by analyzing monitored data from virtual machines and making decisions on their resource configuration with the help of knowledge management (KM). The monitored data stems both from synthetically generated workload categorized in different workload volatility classes and from a real-world scenario: scientific workflow applications in bioinformatics. As KM techniques, we investigate two methods, Case-Based Reasoning and a rule-based approach. We design and implement both of them and evaluate them with the help of a simulation engine. Simulation reveals the feasibility of the CBR approach and major improvements by the rule-based approach considering SLA violations, resource utilization, the number of necessary reconfigurations and time performance for both, synthetically generated and real-world data. Highlights ► We apply knowledge management to guarantee SLAs and low resource wastage in Clouds. ► Escalation levels provide a hierarchical model to structure possible reconfiguration actions. ► Case-Based Reasoning and rule-based approach prove feasibility as KM techniques. ► In-depth evaluation of rule-based approach shows major improvements towards CBR. ► KM is applied to real-world data gathered from scientific bioinformatic workflows.  Introduction The vision of Cloud Computing is to provide computing power as a utility, like gas, electricity or water [1]. For the underlying infrastructure this means that it has to deal with dynamic load changes, ranging from peak performance to utilization gaps. This brings up two issues: on the one hand, the management of a Cloud Computing infrastructure has to guarantee pre-established contracts despite all the dynamism of workload changes. On the other hand it has to efficiently utilize resources and reduce resource wastage. As to the former, the pre-established contracts, so called Service Level Agreements (SLAs), contain Service Level Objectives (SLOs) that represent Quality of Service (QoS) goals, e.g., "storage should be at least 1000 GB", "bandwidth should be at least 10 Mbit/s" or "response time should be less than 2 s", and penalties that have to be paid to the customer if these goals are violated. This work can be integrated into the Foundations of Self-governing ICT Infrastructure (FoSII) project [2], but is on its own completely self-sufficient. The FoSII project aims at developing an infrastructure for autonomic SLA management and enforcement. Besides the already implemented LoM2HiS framework [3] that takes care of monitoring the state of the Cloud infrastructure and its applications, the knowledge management (KM) system presented in this article can be viewed as another building block of the FoSII infrastructure. [4] proposes an approach to manage Cloud infrastructures by means of Autonomic Computing, which in a control loop monitors (M) Cloud parameters, analyzes (A) them, plans (P) actions and executes (E) them; the full cycle is known as MAPE [5]. According to [6] a MAPE-K loop stores knowledge (K) required for decision-making in a knowledge base (KB) that is accessed by the individual phases. This paper addresses the research question of finding a suitable KM system (i.e., a technique of how stored information should be used) and determining how it interacts with the other phases for dynamically and efficiently allocating resources. One of the imminent problems that come up when dealing with the MAPE-K loop is to define possible actions that can be executed at the end of the loop. Due to the plethora of possible reconfiguration actions in Clouds, e.g., increasing/decreasing available memory or storage for virtual machines (VMs), choosing VMs to migrate to selected physical machines (PMs), determining PMs to power on/off, etc., it is not trivial to identify the most beneficial action in a certain situation. On the one hand it is not trivial to retrieve and store all necessary information in a Cloud infrastructure. On the other hand, and more important in our work, dealing with the complexity of recommending an action based on this information is, as we will see, in most cases NP-hard. To tackle this, we structure all possible actions and organize them in a hierarchical model of so called escalation levels. In [7,8] we have shown that approaches using Case Based Reasoning (CBR) and rules as knowledge management techniques succeed in autonomically enacting SLAs and governing important parts of Cloud computing infrastructures. Case Based Reasoning was chosen, because it offers a natural translation of Cloud status information into formal knowledge representation and an easy integration with the MAPE phases. Moreover, it promises to be scalable (as opposed to e.g., Situation Calculus) and easily configurable (as opposed to rule-based systems). Related work has not observed the usage of CBR nor has it evaluated different KM techniques in Cloud environments. However, we determined some drawbacks of CBR as far as its learning performance and its scalability were concerned. Therefore, we also designed and implemented a rule-based knowledge management approach. Using rules [8] we managed to improve not only SLA adherence and resource allocation efficiency as discussed in [7], but also attained an efficient use of reallocation actions and high scalability. Yet, evaluating the KM system on a real environment is not a trivial task because of two reasons: First, Cloud infrastructures usually are huge data centers consisting of hundreds of PMs and even more VMs. Thus, a first step is to simulate the impact of autonomic management decisions on the Cloud infrastructure to determine the performance of the KM decisions. Consequently, we designed and implemented a simulation engine that mimics the MAPE-K cycle on large Clouds. Second, workload data for a large number of VMs has to be provided as input for the simulation. We decided to go two ways: On the one hand, we generated synthetic workload data categorized into different workload volatility classes. These workload volatility classes are determined by the speed and intensity of workload change. On the other hand, we gathered real world data from monitoring scientific workflow applications in the field of bioinformatics [9]. These workflows need a huge, yet unpredictable and varying amount of resources, and are thus-due to the needed flexibility and scalability-a perfect match for a Cloud computing application [10]. The main challenge in this work is to evaluate KM techniques for autonomic SLA enactment in Cloud computing infrastructures that fulfill the three following conflicting goals: (i) achieving low SLA violation rates; (ii) achieving high resource utilization such that the level of allocated but unused resources is as low as possible; and (iii) achieving (i) and (ii) by as few time- and energy-consuming reallocation actions as possible. We will call this problem the resource allocation problem throughout the rest of the paper. The main contributions of this paper are: 1. Design and implementation of a generic (KM-technique agnostic) simulation engine to assess the quality of the KM and decision-making techniques. 2. Partitioning the resource allocation problem for Cloud infrastructures into several subproblems by proposing escalation levels that structure all possible reaction possibilities into different subproblems using a hierarchical model. 3. Design, Implementation and Evaluation of two KM techniques for one escalation level, i.e., VM resource configuration: CBR, and the rule-based approach. 4. Application of the rule-based approach to real-world monitoring data from scientific workflow applications in the field of bioinformatics. The remainder of this work is divided as follows: In Section 2 we present related work. Section 3 gives some background information by explaining the MAPE-K loop and the FoSII project. In Section 4 we structure the problem into the mentioned escalation levels, and in Section 5 we describe how to use the two KM techniques (CBR and rules) to tackle the resource allocation problem for a certain escalation level. Section 6 shows the evaluation of both approaches, especially focusing on the rule-based approach. Section 7 concludes this contribution and points out future work. 